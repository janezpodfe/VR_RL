<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>DQN - Spodbujevalno učenje</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>
  <link href='https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "DQN";
    var mkdocs_page_input_path = "car_DQN.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Spodbujevalno učenje</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="tocbase current">
    
    
      


  <li class="navtree toctree-l1 inactive">
    <a class="" href="..">Uvod</a>
  </li>
    
      


  <li class="navtree toctree-l1 inactive">
    <a class="" href="../conda_env/">Priprava okolja</a>
  </li>
    
      
  <li class="navtree toctree-l1 label">
    <p class="caption">Primer Cliff Walking</p>
  </li>


  

  
    <li class="navtree toctree-l1 group">
      <ul class="navtree subnav-l1 current">
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../cliff/">Primer okolja *Cliff Walking*</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../cliff2/">Prikaz Q tabele</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../cliff3/">Parametri učenja in eksploracija</a>
  </li>
        
      </ul>
    </li>
    
      
  <li class="navtree toctree-l1 label">
    <p class="caption">Primer Mountain Car</p>
  </li>


  

  
    <li class="navtree toctree-l1 group">
      <ul class="navtree subnav-l1 current">
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../car/">MountainCar primer</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../load_car/">Test agenta</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../car_reward/">Izpis nagrade</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../car_action/">Prikaz akcij glede na Q tabelo</a>
  </li>
        
          


  
    
    <li class="navtree toctree-l2 page current">
      <a class="current" href="./">
        DQN
          <span class="toctree-expand"></span>
      </a>
    </li>
    
      

  <li class="toctree-l2 current with-children">
    <a href="#ucenje-z-nevronskimi-mrezami-z-metodo-dqn">
      Učenje z nevronskimi mrežami z metodo DQN
      <span class="toctree-expand"></span>
    </a>
  </li>



  <li class="toctree-l2 current">
    <ul class="subnav-l2 current">
    
      
          

  <li class="toctree-l3 current with-children">
    <a href="#globoko-spodbujevalno-ucenje">
      Globoko spodbujevalno učenje
      <span class="toctree-expand"></span>
    </a>
  </li>



  <li class="toctree-l3 current">
    <ul class="subnav-l3 current">
    
      
        <li class="toctree-l4">
          <a class="toctree-l5" href="#dqn">DQN</a>
        </li>
    
      
        <li class="toctree-l4">
          <a class="toctree-l5" href="#ppo">PPO</a>
        </li>
    
      
        <li class="toctree-l4">
          <a class="toctree-l5" href="#a2c">A2C</a>
        </li>
    
    </ul>
  </li>

      
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#prakticna-uporaba">Praktična uporaba</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#python-skripta-za-ucenje-agenta">Python skripta za učenje agenta</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#python-skripta-za-testiranje-agenta">Python skripta za testiranje agenta</a>
        </li>
    
    </ul>
  </li>


  
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../save_models/">Shranjevanje agentov in logiranje</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../carSB3Contrib/">Uporaba drugih algoritmov za učenje</a>
  </li>
        
      </ul>
    </li>
    
      
  <li class="navtree toctree-l1 label">
    <p class="caption">Primer Cart Pole</p>
  </li>


  

  
    <li class="navtree toctree-l1 group">
      <ul class="navtree subnav-l1 current">
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../cart/">Cartpole primer</a>
  </li>
        
      </ul>
    </li>
    
      
  <li class="navtree toctree-l1 label">
    <p class="caption">Circle Environment</p>
  </li>


  

  
    <li class="navtree toctree-l1 group">
      <ul class="navtree subnav-l1 current">
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../circ_env_slo/">Okolje Circle Envrionment</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../instalCircEnv/">Inštalacija paketa CircEnv</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../move_agent_mouse/">Premik agenta z miško</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../circ_env_tocka/">Premik v točko</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../circ_env_pak/">Dotik s pakom</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../circ_env_pak_rob/">Pomik paka v gol</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../circ_env_pak_gol/">Pomik paka v gol 2</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../circ_env_pak_gol2/">Pomik paka v gol 3</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../circ_env_obj_gol/">Pomik naključnega objekta v gol</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../circ_env_train/">Učenje</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../circ_env_robot/">Povezovanje z robotom</a>
  </li>
        
      </ul>
    </li>
    
      
  <li class="navtree toctree-l1 label">
    <p class="caption">Hockey Environment</p>
  </li>


  

  
    <li class="navtree toctree-l1 group">
      <ul class="navtree subnav-l1 current">
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../hockey_env/">Hockey Environment</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../hockey_help_snippets/">Funkcije za pomoč pri programiranju</a>
  </li>
        
      </ul>
    </li>
    
  </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Spodbujevalno učenje</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Primer Mountain Car &raquo;</li>
        
      
    
    <li>DQN</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="ucenje-z-nevronskimi-mrezami-z-metodo-dqn">Učenje z nevronskimi mrežami z metodo DQN</h1>
<h2 id="globoko-spodbujevalno-ucenje">Globoko spodbujevalno učenje</h2>
<p><img alt="alt text" src="https://spinningup.openai.com/en/latest/_images/rl_algorithms_9_15.svg" /></p>
<p><a href="https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html">https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html</a></p>
<h3 id="dqn">DQN</h3>
<p>Q-učenje je algoritma za spodbujevalno učenje, ki uporablja tabelo za shranjevanje vrednosti Q za vsak par stanje-akcija. Ker pa prostor stanj postaja vse večji in kompleksnejši, postane shranjevanje vseh vrednosti Q v tabeli nepraktično. Tu pride na vrsto DQN.</p>
<p>DQN je vrsta algoritma za Q-učenje, ki za izračun (približka) vrednosti Q uporablja nevronsko mrežo. Nevronska mreža sprejme stanje kot vhod in kot izhod izračuna vrednosti Q za vsako možno akcijo. Mreža je naučena s kombinacijo ponovitve izkušenj in »target« nevronske mreže za izboljšanje stabilnosti in učinkovitosti.</p>
<blockquote>
<p><strong>Tehnika ponovitve izkušenj</strong> se uporablja za izboljšanje učinkovitosti učenja. Namesto da bi nevronsko mrežo učili takoj na vsaki izkušnji, se izkušnje shranijo v spomin in se iz njega naključno izbere serija izkušenj za učenje mreže. To ima več prednosti. Prvič, pomaga prekiniti korelacijo med zaporednimi izkušnjami, kar lahko zmanjša verjetnost, da bo mreža obtičalo v lokalnem optimumu. Drugič, nevronski mreži omogoča, da se uči iz širšega razpona izkušenj, kar lahko privede do boljše posplošitve in boljšega delovanja.</p>
<p><strong>»Target« nevronska mreža</strong> je ločena kopija glavnega nevronske mreže, ki se med učenjem uporablja za izračun ciljnih (»target«) vrednosti Q. V DQN uporabljamo »target« nevronsko mrežo za reševanje problema, znanega kot "problem premikajoče se tarče". Ta težava nastane, ko uporabimo isto omrežje za izračunavanje napovedi vrednosti Q in ciljnih vrednosti Q ter po vsaki napovedi posodobimo uteži nevronske mreže. To lahko povzroči hitro in nestanovitno spreminjanje ciljnih vrednosti Q, kar lahko privede do nestabilnosti v procesu učenja. Za rešitev te težave uporabimo »target« nevronsko mrežo, ki je kopija glavne nevronske mreže, vendar z zamrznjenimi parametri. »Target« nevronska mreža se uporablja za izračun ciljnih vrednosti Q, uteži glavnega omrežja pa se redno posodabljajo le z uporabo ciljnih vrednosti Q, ki jih izračuna ciljno omrežje. To stabilizira postopek učenja in omrežju omogoča učinkovitejše učenje.</p>
</blockquote>
<p>Najprej začnemo z vhodnim stanjem kor vhodom v nevronsko mrežo. Mreža nato vrne vrednosti Q za vsako možno akcijo. Podobno kot pri Q-učenju ne izberemo akcije z najvišjo vrednostjo Q. Namesto tega uporabimo tehniko, imenovano "epsilon-greedy exploration", kjer z verjetnostjo epsilon izberemo naključno akcijo in z verjetnostjo 1-epsilon izberemo akcijo z najvišjo vrednostjo Q. To algoritmu omogoča, da raziskuje nove akcije in potencialno najde boljše rešitve. Ko izberemo akcijo, jo izvedemo in opazujemo dobljeno nagrado in novo stanje. Ta izkušnja se shrani v spomin za ponovitev, ki ga bomo pozneje uporabili za učenje mreže.</p>
<p>Nato naključno izberemo serijo izkušenj iz spomina in jih uporabimo za učenje mreže. Vendar mreže ne želimo vedno znova učiti na istih izkušnjah, saj to lahko privede do pojava »overfitting«. Za rešitev te težave uporabimo »target« nevronsko mrežo, ki je kopija glavnega nevronske mreže, vendar z zamrznjenimi parametri. To »target« nevronsko mrežo uporabimo za izračun končnih vrednosti Q za vsako izkušnjo, nato pa posodobimo parametre glavne mreže, da čim bolj zmanjšamo razliko med napovedanimi vrednostmi Q in končnimi vrednostmi Q. Ta postopek se ponavlja iterativno, pri čemer nevronska mreža nenehno izboljšuje svoje ocene vrednosti Q, ko se uči iz izkušenj.</p>
<p>Če povzamemo, je DQN vrsta algoritma za Q-učenje, ki za oceno vrednosti Q uporablja nevronsko mrežo. Združuje ponovitev izkušenj in »target« nevronsko mrežo za izboljšanje stabilnosti in učinkovitosti. Z uporabo te metode lahko obravnavamo večje in bolj zapletene prostore stanj ter na koncu dosežemo boljše rezultate kot z Q-metodo.</p>
<h3 id="ppo">PPO</h3>
<p>DQN (Deep Q-Network) in PPO (Proximal Policy Optimization) sta priljubljeni metodi za spodbujevalno učenje, ki se uporabljata za učenje agentov za izvajanje določenih nalog. Vendar se razlikujeta glede na pristop in cilje. DQN je na Q vrednosti temelječa metoda spodbujevalnega učenja, ki uči vrednosti Q (pričakovane prihodnje nagrade) za vsak par stanje-akcija. Cilj DQN je naučiti se optimalno funkcijo Q, ki povezuje stanja z akcijami. To dosežemo z učenjem globoke nevronske mreže za oceno vrednosti Q z uporabo kombinacije ponovitve izkušenj in »target« nevronske mreže.</p>
<p>PPO pa je metoda spodbujevalnega učenja na podlagi strategije, ki se neposredno uči strategija za preslikavo iz stanj v akcije. Cilj PPO je maksimizirati pričakovano kumulativno nagrado agenta z iskanjem optimalne strategije. To se doseže z optimizacijo nadomestne objektivne funkcije, ki zagotavlja, da se nova strategija ne razlikuje preveč od stare.</p>
<p>Čeprav se lahko tako DQN kot PPO uporabljata za diskretne in zvezne prostore akcij, se razlikujeta po učinkovitosti vzorčenja, stabilnosti in enostavnosti izvajanja.</p>
<p>DQN je na splošno manj vzorčno učinkovit kot PPO, saj za učenje natančne funkcije Q potrebuje veliko število učnih vzorcev. Vendar je DQN znana po svoji stabilnosti in se uspešno uporablja v številnih aplikacijah, tudi v robotiki.</p>
<p>Po drugi strani pa je PPO znana po svoji učinkovitosti vzorčenja in je dokazano dosegla vrhunske rezultate pri številnih nalogah zveznega vodenja. PPO je tudi razmeroma enostavna za izvajanje, saj ne potrebuje ponovitve izkušenj ali ločene »target« nevronske mreže.</p>
<p>Čeprav sta DQN in PPO zmogljivi metodi učenja za spodbujevalno učenje, se razlikujeta po pristopu in ciljih. DQN je metoda, ki temelji na vrednosti in se uči optimalne funkcije Q, PPO pa je metoda, ki temelji na strategiji in se neposredno uči optimalne strategije. </p>
<h3 id="a2c">A2C</h3>
<p>A2C pa je metoda spodbujevalnega učenja, ki temelji na strategiji in se neposredno uči strategije (preslikava med stanji in akcijami). Cilj A2C je maksimizirati pričakovano kumulativno nagrado agenta z iskanjem optimalne strategije, podobno kot PPO. To se doseže s hkratnim učenjem dveh nevronskih mrež: »actor« nevronska mreža, ki aproksimira strategijo, in »critic« nevronske mreže, ki ocenjuje funkcijo vrednosti.</p>
<p>Ključna razlika med DQN in A2C je, da je DQN metoda »off-policy”, kar pomeni, da se uči optimalne vrednosti Q z uporabo ločene strategije, medtem ko je A2C metoda »on-policy”, kar pomeni, da se uči strategije in funkcije vrednosti neposredno iz trenutne strategije.</p>
<p>Druga razlika je, da se DQN lahko uporablja tako za diskretne kot za zvezne prostore akcij, medtem ko se A2C običajno uporablja za diskretne prostore akcij. Poleg tega je A2C na splošno bolj vzorčno učinkovita kot DQN, saj se lahko uči iz delnih trajektorij, medtem ko DQN za posodobitev svojih vrednosti Q potrebuje celotne trajektorije.</p>
<blockquote>
<p>Trajektorija $\tau$ je sekvenca parov $stanje_0$-&gt;$akcija_0$-&gt;$stanje_1$-&gt;$akcija_1$-&gt;...</p>
</blockquote>
<p>Ključna razlika med PPO in A2C je v tem, da PPO uporablja »clipped« objektivno funkcijo, da prepreči prevelike spremembe strategije ob vsaki posodobitvi, medtem ko A2C uporablja »advantage« funkcijo za oceno kakovosti vsake akcije glede na trenutno strategijo.</p>
<p>Druga razlika je, da je PPO na splošno bolj vzorčno učinkovit kot A2C, saj uporablja tehniko, imenovano vzorčenje po pomembnosti, za popravke posodobitev gradienta. Vzorčenje po pomembnosti omogoča, da se PPO uči iz stare strategije, kar lahko izboljša učinkovitost vzorčenja.</p>
<p>Čeprav sta tako PPO kot A2C učinkoviti metodi za spodbujevalno učenje, se razlikujeta po pristopu in ciljih. PPO je metoda, ki temelji na strategiji in se uči optimalne strategije z uporabo optimizacije in »clipped« objektivne funkcije, A2C pa je prav tako metoda, ki temelji na strategiji in se uči optimalne strategije in funkcije vrednosti z uporabo »advantage« funkcije prednosti. </p>
<blockquote>
<p><strong>“Advantage” funkcija</strong> je temeljni koncept spodbujevalnega učenja, ki se uporablja za oceno kakovosti vsake akcije agenta glede na trenutno strategijo. Meri, koliko boljša je akcija v primerjavi s povprečno akcijo izvedeno na podlagi trenutne strategije, in se uporablja za posodabljanje strategije in funkcije vrednosti.</p>
<p>Bolj formalno je funkcija prednosti A(s, a) opredeljena kot razlika med vrednostjo Q (pričakovana kumulativna nagrada) za akcijo <em>a</em> v stanju <em>s</em> in funkcijo vrednosti (pričakovana kumulativna nagrada po trenutni strategiji) stanja s:</p>
<p>A(s, a) = Q(s, a) - V(s)</p>
<p>“Advantage” funkcija je pomemben gradnik številnih algoritmov spodbujevalnega učenja, kot sta A2C in PPO. Agentu omogoča razlikovanje med dobrimi in slabimi akcijami z izračunom pričakovanega izboljšanja dolgoročne nagrade za določeno akcijo v primerjavi s povprečno akcijo izvedeno na podlagi trenutne strategije. Ta informacija se uporabi za posodobitev strategije na način, ki agenta spodbuja k sprejemanju akcij, ki so boljša od povprečne akcije.</p>
<p>Eden od načinov za oceno funkcije prednosti je uporaba napake TD (napake časovne razlike) med ocenjeno funkcijo vrednosti in opazovano nagrado. To lahko storimo z metodo, imenovano enostopenjsko učenje TD (temporal difference), ki v vsakem časovnem koraku posodobi funkcijo vrednosti in “advantage” funkcijo. Drug pristop je uporaba natančnejše ocene “advantage” funkcije, kot je posplošena ocena prednosti (GAE), ki združuje več časovnih korakov, da zagotovi stabilnejšo oceno “advantage” funkcije.</p>
<p>“Advantage” funkcija je ključen gradnik algoritmov spodbujevalnega učenja, ki se uporablja za oceno kakovosti vsake akcije agenta. Agentu omogoča, da se nauči, katere akcije so boljše od drugih, ter ustrezno posodobi strategijo in funkcijo vrednosti.</p>
</blockquote>
<p><strong>Primer učenja z DQN in PPO</strong>
<img alt="alt text" src="../images/Screenshot_2023-04-13_17-17-43.png" /></p>
<h2 id="prakticna-uporaba">Praktična uporaba</h2>
<ul>
<li>Učenje z nevronskimi mrežami z metodo DQN</li>
<li>Uporabimo python paket Stable Baselines3 (SB3)</li>
<li><a href="https://stable-baselines3.readthedocs.io/en/master/index.html">Stable-Baselines3 Docs</a></li>
<li>Stable Baselines3 omogoča celo vrsto drugih algoritmov<ul>
<li>A2C</li>
<li>PPO</li>
</ul>
</li>
<li>Razširitev SB3 Contrib<ul>
<li>dodatni sodobnejši algoritmi</li>
<li><a href="https://stable-baselines3.readthedocs.io/en/master/guide/sb3_contrib.html">SB3 Contrib dokumentacije</a></li>
<li><a href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">Github repozitorij</a></li>
</ul>
</li>
</ul>
<p><strong>Q tabela</strong>
<img alt="alt text" src="../images/Picture8.png" /></p>
<p><strong>Aproksimacija Q tabele s funkcijami</strong></p>
<p><em>Diskretne akcije</em>
<img alt="alt text" src="../images/Picture9b.png" /></p>
<p><em>Zvezne akcije</em>
<img alt="alt text" src="../images/Picture8b.png" /></p>
<p><em>Aproksimacija Q tabele z nevronsko mrežo</em>
<img alt="alt text" src="../images/Picture9.png" /></p>
<h2 id="python-skripta-za-ucenje-agenta">Python skripta za učenje agenta</h2>
<ol>
<li>Nova python skripta</li>
<li>
<p>Incializacija okolja in učenja</p>
<p><div class="language-py highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span> <span class="nn">gym</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">DQN</span> 
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;MountainCar-v0&quot;</span><span class="p">)</span>
</span></code></pre></div>
3. Preverimo prostor akcij in opazovanja</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;Actions = &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;Obs space high = &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;Obs space low&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>Inicializiramo učenje agenta</p>
</li>
<li>
<p>Podatki za inicializacijo so na <a href="https://github.com/sgoodfriend/rl-algo-impls/blob/main/hyperparams/dqn.yml">spletni strani</a> ter na <a href="https://github.com/DLR-RM/rl-baselines3-zoo/tree/master/hyperparams">rl-baselines3-zoo</a></p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">policy_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">net_arch</span><span class="o">=</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="s1">&#39;MlpPolicy&#39;</span><span class="p">,</span> 
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>            <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">4e-3</span><span class="p">,</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>            <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>            <span class="n">buffer_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>            <span class="n">learning_starts</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>            <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>            <span class="n">target_update_interval</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>            <span class="n">train_freq</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>            <span class="n">gradient_steps</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>            <span class="n">exploration_fraction</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>            <span class="n">exploration_final_eps</span><span class="o">=</span><span class="mf">0.07</span><span class="p">,</span>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>            <span class="n">policy_kwargs</span><span class="o">=</span><span class="n">policy_kwargs</span><span class="p">,</span>
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>            <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="__span-2-16"><a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
</span><span id="__span-2-17"><a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>Učenje agenta</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mf">1.2e5</span><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>Shranimo model</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;dqn_car&quot;</span><span class="p">)</span>
</span></code></pre></div>
</li>
</ol>
<h2 id="python-skripta-za-testiranje-agenta">Python skripta za testiranje agenta</h2>
<ol>
<li>Nova python skripta</li>
<li>
<p>Incializacija okolja in učenja</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="kn">import</span> <span class="nn">gym</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">DQN</span> 
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="kn">from</span> <span class="nn">stable_baselines3.common.evaluation</span> <span class="kn">import</span> <span class="n">evaluate_policy</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;MountainCar-v0&quot;</span><span class="p">)</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;Actions = &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;Obs space high = &quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;Obs space low&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>Naložimo in incializiramo agenta</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dqn_car&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>Zaženemo in testiramo agenta</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="n">mean_reward</span><span class="p">,</span> <span class="n">std_reward</span> <span class="o">=</span> <span class="n">evaluate_policy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">(),</span> <span class="n">n_eval_episodes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Mean reward: </span><span class="si">{</span><span class="n">mean_reward</span><span class="si">}</span><span class="s1">, Std reward: </span><span class="si">{</span><span class="n">std_reward</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>    <span class="n">action</span><span class="p">,</span> <span class="n">_state</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>    <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>    <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>        <span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span></code></pre></div>
</li>
</ol>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../save_models/" class="btn btn-neutral float-right" title="Shranjevanje agentov in logiranje">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../car_action/" class="btn btn-neutral" title="Prikaz akcij glede na Q tabelo"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../car_action/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../save_models/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
